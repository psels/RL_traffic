{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from state import get_state, queue, get_state_per_traffic_light\n",
    "import os\n",
    "import traci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/EclipseSUMO.framework/Versions/1.22.0/EclipseSUMO/bin/sumo-gui\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "sumo_bin = os.getenv(\"SUMO\")\n",
    "sumo_gui_bin = os.getenv(\"SUMO-GUI\")\n",
    "simulConfig = \"double_traffic/double_traffic.sumo.cfg\"\n",
    "\n",
    "\n",
    "#sumo_bin = r\"C:/Program Files/rl_project/Eclipse/Sumo/bin/sumo.exe\"\n",
    "#sumo_gui_bin = os.getenv(\"SUMO-GUI\")\n",
    "#sumo_gui_bin = r\"C:/Program Files/rl_project/Eclipse/Sumo/bin/sumo-gui.exe\"\n",
    "#simulConfig = r\"double_traffic/doube_traffic.sumo.cfg\"\n",
    "#sumoConfig3 = r\"Traditional_traffic/traditional_traffic.sumo.cfg\"\n",
    "\n",
    "\n",
    "\n",
    "print(sumo_gui_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.random import set_seed\n",
    "from collections import deque\n",
    "from tensorflow import keras\n",
    "from tensorflow import reduce_sum, reduce_mean, one_hot, GradientTape\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pr/.pyenv/versions/3.10.6/envs/sumo_env/lib/python3.10/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "/Users/pr/.pyenv/versions/3.10.6/envs/sumo_env/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m132\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,268</span> (12.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,268\u001b[0m (12.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,268</span> (12.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,268\u001b[0m (12.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seed(42)  # extra code – ensures reproducibility on the CPU\n",
    "\n",
    "input_shape = (64,)  # == env.observation_space.shape\n",
    "n_outputs = 4  # == env.action_space.n\n",
    "#[((Phase(duration=30.0, state='GGrGrrGGrGrr', minDur=30.0, maxDur=30.0), Phase(duration=20.0, state='grGgrrgrGgrr', minDur=20.0, maxDur=20.0), Phase(duration=30.0, state='GrrGGrGrrGGr', minDur=30.0, maxDur=30.0), Phase(duration=20.0, state='grrgrGgrrgrG', minDur=20.0, maxDur=20.0)), [0, 2, 4, 6])]\n",
    "model_action_one_tf_light = Sequential([\n",
    "    layers.Dense(32,activation=tf.keras.layers.LeakyReLU(alpha=0.01), input_shape=input_shape),\n",
    "    layers.Dense(32, activation=tf.keras.layers.LeakyReLU(alpha=0.01)),\n",
    "    layers.Dense(n_outputs, activation= 'linear')])\n",
    "model_action_one_tf_light.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)  # extra code – ensures reproducibility on the CPU\n",
    "# receives states and actions of both agent 1 and 2\n",
    "input_shape = [184]  # == env.observation_space.shape\n",
    "n_outputs = 4  # == env.action_space.n\n",
    "#[((Phase(duration=30.0, state='GGrGrrGGrGrr', minDur=30.0, maxDur=30.0), Phase(duration=20.0, state='grGgrrgrGgrr', minDur=20.0, maxDur=20.0), Phase(duration=30.0, state='GrrGGrGrrGGr', minDur=30.0, maxDur=30.0), Phase(duration=20.0, state='grrgrGgrrgrG', minDur=20.0, maxDur=20.0)), [0, 2, 4, 6])]\n",
    "model__critic_action_one_tf_light = Sequential([\n",
    "    layers.Dense(32,activation=tf.keras.layers.LeakyReLU(alpha=0.01), input_shape=input_shape),\n",
    "    layers.Dense(32, activation=tf.keras.layers.LeakyReLU(alpha=0.01)),\n",
    "    layers.Dense(n_outputs, activation= 'linear')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)  # extra code – ensures reproducibility on the CPU\n",
    "\n",
    "input_shape = (64,)  # == env.observation_space.shape\n",
    "n_outputs = 4  # == env.action_space.n\n",
    "#[((Phase(duration=30.0, state='GGrGrrGGrGrr', minDur=30.0, maxDur=30.0), Phase(duration=20.0, state='grGgrrgrGgrr', minDur=20.0, maxDur=20.0), Phase(duration=30.0, state='GrrGGrGrrGGr', minDur=30.0, maxDur=30.0), Phase(duration=20.0, state='grrgrGgrrgrG', minDur=20.0, maxDur=20.0)), [0, 2, 4, 6])]\n",
    "model_action_second_tf_light = Sequential([\n",
    "    layers.Dense(32,activation=tf.keras.layers.LeakyReLU(alpha=0.01), input_shape=input_shape),\n",
    "    layers.Dense(32, activation=tf.keras.layers.LeakyReLU(alpha=0.01)),\n",
    "    layers.Dense(n_outputs, activation= 'linear')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)  # extra code – ensures reproducibility on the CPU\n",
    "# receives states and actions of both agent 1 and 2\n",
    "input_shape = [184]  # == env.observation_space.shape\n",
    "n_outputs = 4  # == env.action_space.n\n",
    "#[((Phase(duration=30.0, state='GGrGrrGGrGrr', minDur=30.0, maxDur=30.0), Phase(duration=20.0, state='grGgrrgrGgrr', minDur=20.0, maxDur=20.0), Phase(duration=30.0, state='GrrGGrGrrGGr', minDur=30.0, maxDur=30.0), Phase(duration=20.0, state='grrgrGgrrgrG', minDur=20.0, maxDur=20.0)), [0, 2, 4, 6])]\n",
    "model__critic_second_tf_light = Sequential([\n",
    "    layers.Dense(32,activation=tf.keras.layers.LeakyReLU(alpha=0.01), input_shape=input_shape),\n",
    "    layers.Dense(32, activation=tf.keras.layers.LeakyReLU(alpha=0.01)),\n",
    "    layers.Dense(n_outputs, activation= 'linear')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def epsilon_greedy_policy(state_tf_one, state_tf_two,epsilon=0):\n",
    "#     if np.random.rand() < epsilon:\n",
    "#         return np.random.randint(n_outputs), np.random.randint(n_outputs)  # random action\n",
    "#     else:\n",
    "#         Q_values_tf_one = model_action_one_tf_light.predict(state_tf_one[np.newaxis], verbose=0)[0]\n",
    "#         Q_values_tf_two = model_action_second_tf_light.predict(state_tf_two[np.newaxis], verbose=0)[0]\n",
    "\n",
    "#         print(f\"state : {state_tf_one, state_tf_two}\")\n",
    "#         print(f\"Q_values : {Q_values_tf_one, Q_values_tf_two}\")\n",
    "#         return Q_values_tf_one.argmax(), Q_values_tf_two.argmax()  # optimal action according to the DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_experiences(batch_size):\n",
    "    indices = np.random.randint(len(replay_buffer), size=batch_size)\n",
    "    batch = [replay_buffer[index] for index in indices]\n",
    "    states, rewards, next_states = [\n",
    "        np.array([experience[field_index] for experience in batch])\n",
    "        for field_index in range(9)\n",
    "    ]\n",
    "    return states, rewards, next_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_agent(agent_idx, batch, agents, gamma=0.95):\n",
    "    # batch = (states, actions, rewards, next_states)\n",
    "    states, actions, rewards, next_states = batch\n",
    "\n",
    "    agent = agents[agent_idx]\n",
    "\n",
    "    ### Critic update ###\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Actions suivantes pour chaque agent avec target actor\n",
    "        next_actions = [agents[i].target_actor(next_states[:, i, :]) for i in range(len(agents))]\n",
    "        next_actions = tf.concat(next_actions, axis=-1)\n",
    "\n",
    "        # Critic target Q\n",
    "        target_Q = agent.target_critic([next_states, next_actions])\n",
    "        target_Q = rewards[:, agent_idx] + gamma * target_Q\n",
    "\n",
    "        # Current Q avec critic principal\n",
    "        current_actions = tf.concat(actions, axis=-1)\n",
    "        current_Q = agent.critic([states, current_actions])\n",
    "\n",
    "        critic_loss = tf.reduce_mean(tf.square(target_Q - current_Q))\n",
    "\n",
    "    critic_grad = tape.gradient(critic_loss, agent.critic.trainable_variables)\n",
    "    agent.critic_optimizer.apply_gradients(zip(critic_grad, agent.critic.trainable_variables))\n",
    "\n",
    "    ### Actor update ###\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Actions proposées par les actors\n",
    "        current_actions = []\n",
    "        for i in range(len(agents)):\n",
    "            if i == agent_idx:\n",
    "                current_action = agent.actor(states[:, i, :])\n",
    "            else:\n",
    "                current_action = actions[i]  # on stoppe le gradient sur les autres\n",
    "            current_actions.append(current_action)\n",
    "\n",
    "        current_actions = tf.concat(current_actions, axis=-1)\n",
    "\n",
    "        # Maximise Q donc minimise -Q\n",
    "        actor_loss = -tf.reduce_mean(agent.critic([states, current_actions]))\n",
    "\n",
    "    actor_grad = tape.gradient(actor_loss, agent.actor.trainable_variables)\n",
    "    agent.actor_optimizer.apply_gradients(zip(actor_grad, agent.actor.trainable_variables))\n",
    "\n",
    "    return critic_loss, actor_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Environment variable SUMO_HOME is not set properly, disabling XML validation. Set 'auto' or 'always' for web lookups.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (64,)\n",
      "shape (64,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "action [[1]]\n",
      "shape (64,)\n",
      "shape (64,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action [[0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2c/jlpbrr154jg9cfp1pzbh8x5h0000gn/T/ipykernel_72344/2183737402.py:109: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  traci.trafficlight.setPhase(traffic_light_ids[0],2*int(action_tf_one))\n",
      "/var/folders/2c/jlpbrr154jg9cfp1pzbh8x5h0000gn/T/ipykernel_72344/2183737402.py:110: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  traci.trafficlight.setPhase(traffic_light_ids[0],2*int(action_tf_two))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (64,)\n",
      "shape (64,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action [[1]]\n",
      "shape (64,)\n",
      "shape (64,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action [[2]]\n",
      "shape (64,)\n",
      "shape (64,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action [[2]]\n",
      "shape (64,)\n",
      "shape (64,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action [[2]]\n",
      "shape (64,)\n",
      "shape (64,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action [[2]]\n",
      "shape (64,)\n",
      "shape (64,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action [[0]]\n",
      "shape (64,)\n",
      "shape (64,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action [[2]]\n",
      "Stepshape (64,)ms ~= 10.00*RT, ~111000.00UPS, TraCI: 0ms, vehicles TOT 228 ACT 111 BUF 3) \n",
      "shape (64,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action [[0]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Binding inputs to tf.function failed due to `missing a required argument: 'agents'`. Received args: (0, deque([(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), array([[1],\n       [3]]), array([[0],\n       [0]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])), (array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), array([[0],\n       [0]]), array([[-7],\n       [-7]]), array([0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0])), (array([0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0]), array([[1],\n       [3]]), array([[-19],\n       [-14]]), array([0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n       1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 5, 0, 1, 0, 1, 0,\n       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 2, 0, 0, 0,\n       1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1,\n       0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 0, 0, 1, 0, 0, 0, 0, 0])), (array([0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n       1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 5, 0, 1, 0, 1, 0,\n       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 2, 0, 0, 0,\n       1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1,\n       0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 0, 0, 1, 0, 0, 0, 0, 0]), array([[2],\n       [2]]), array([[-16],\n       [-13]]), array([0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       3, 0, 0, 0, 2, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 6, 1, 2, 0, 2, 0,\n       1, 0, 2, 0, 0, 1, 1, 0, 0, 0, 5, 0, 0, 0, 2, 2, 0, 1, 1, 0, 0, 0,\n       1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 1, 0, 1, 0, 0, 0, 0, 2, 2, 0, 1, 0, 0, 0, 0, 1, 4, 2, 1, 1,\n       2, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 2, 0, 1, 0, 1, 0])), (array([0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       3, 0, 0, 0, 2, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 6, 1, 2, 0, 2, 0,\n       1, 0, 2, 0, 0, 1, 1, 0, 0, 0, 5, 0, 0, 0, 2, 2, 0, 1, 1, 0, 0, 0,\n       1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 1, 0, 1, 0, 0, 0, 0, 2, 2, 0, 1, 0, 0, 0, 0, 1, 4, 2, 1, 1,\n       2, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 2, 0, 1, 0, 1, 0]), array([[2],\n       [2]]), array([[-15],\n       [-28]]), array([0, 0, 0, 0, 0, 0, 6, 2, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 1, 0,\n       5, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 6, 2, 1, 1, 1, 0,\n       0, 0, 5, 0, 1, 0, 2, 0, 1, 0, 5, 0, 0, 0, 1, 2, 0, 2, 2, 0, 0, 0,\n       2, 0, 2, 0, 0, 0, 0, 0, 4, 0, 4, 0, 3, 0, 0, 0, 1, 0, 0, 0, 1, 3,\n       0, 0, 2, 0, 2, 0, 2, 0, 0, 1, 3, 0, 2, 0, 0, 0, 0, 1, 5, 1, 4, 0,\n       3, 0, 0, 0, 2, 0, 0, 0, 2, 5, 0, 1, 2, 0, 2, 0, 2, 0])), (array([0, 0, 0, 0, 0, 0, 6, 2, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 1, 0,\n       5, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 6, 2, 1, 1, 1, 0,\n       0, 0, 5, 0, 1, 0, 2, 0, 1, 0, 5, 0, 0, 0, 1, 2, 0, 2, 2, 0, 0, 0,\n       2, 0, 2, 0, 0, 0, 0, 0, 4, 0, 4, 0, 3, 0, 0, 0, 1, 0, 0, 0, 1, 3,\n       0, 0, 2, 0, 2, 0, 2, 0, 0, 1, 3, 0, 2, 0, 0, 0, 0, 1, 5, 1, 4, 0,\n       3, 0, 0, 0, 2, 0, 0, 0, 2, 5, 0, 1, 2, 0, 2, 0, 2, 0]), array([[2],\n       [2]]), array([[-23],\n       [-29]]), array([0, 0, 1, 0, 4, 0, 6, 3, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 2, 0, 2, 0,\n       6, 0, 0, 0, 0, 3, 0, 2, 3, 0, 0, 0, 2, 0, 4, 0, 6, 4, 0, 0, 1, 1,\n       0, 0, 5, 0, 0, 0, 2, 0, 2, 0, 6, 0, 0, 0, 0, 4, 0, 3, 3, 0, 0, 0,\n       3, 0, 2, 0, 0, 0, 0, 0, 6, 0, 6, 0, 3, 0, 0, 0, 2, 0, 2, 0, 6, 5,\n       0, 0, 3, 0, 2, 0, 3, 0, 0, 0, 3, 0, 2, 0, 0, 0, 1, 0, 6, 1, 6, 0,\n       3, 0, 0, 0, 2, 0, 2, 0, 6, 5, 0, 0, 4, 0, 3, 0, 4, 0])), (array([0, 0, 1, 0, 4, 0, 6, 3, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 2, 0, 2, 0,\n       6, 0, 0, 0, 0, 3, 0, 2, 3, 0, 0, 0, 2, 0, 4, 0, 6, 4, 0, 0, 1, 1,\n       0, 0, 5, 0, 0, 0, 2, 0, 2, 0, 6, 0, 0, 0, 0, 4, 0, 3, 3, 0, 0, 0,\n       3, 0, 2, 0, 0, 0, 0, 0, 6, 0, 6, 0, 3, 0, 0, 0, 2, 0, 2, 0, 6, 5,\n       0, 0, 3, 0, 2, 0, 3, 0, 0, 0, 3, 0, 2, 0, 0, 0, 1, 0, 6, 1, 6, 0,\n       3, 0, 0, 0, 2, 0, 2, 0, 6, 5, 0, 0, 4, 0, 3, 0, 4, 0]), array([[2],\n       [2]]), array([[-12],\n       [ 10]]), array([0, 0, 2, 0, 4, 0, 6, 6, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 2, 0, 2, 0,\n       6, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 4, 0, 6, 6, 4, 1, 1, 1,\n       1, 1, 8, 0, 0, 2, 3, 0, 2, 0, 6, 0, 1, 0, 0, 1, 1, 0, 3, 0, 0, 0,\n       3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0, 2, 0, 6, 7,\n       0, 0, 0, 0, 0, 0, 6, 0, 1, 4, 4, 0, 3, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n       4, 0, 0, 0, 3, 0, 3, 0, 6, 8, 2, 0, 1, 0, 0, 0, 6, 0])), (array([0, 0, 2, 0, 4, 0, 6, 6, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 2, 0, 2, 0,\n       6, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 4, 0, 6, 6, 4, 1, 1, 1,\n       1, 1, 8, 0, 0, 2, 3, 0, 2, 0, 6, 0, 1, 0, 0, 1, 1, 0, 3, 0, 0, 0,\n       3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0, 2, 0, 6, 7,\n       0, 0, 0, 0, 0, 0, 6, 0, 1, 4, 4, 0, 3, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n       4, 0, 0, 0, 3, 0, 3, 0, 6, 8, 2, 0, 1, 0, 0, 0, 6, 0]), array([[0],\n       [1]]), array([[ -3],\n       [-12]]), array([0, 0, 2, 0, 4, 0, 6, 7, 0, 0, 0, 0, 2, 0, 9, 0, 0, 0, 3, 0, 2, 0,\n       6, 0, 0, 0, 0, 1, 0, 0, 3, 0, 1, 0, 2, 0, 4, 0, 6, 8, 0, 1, 0, 0,\n       2, 0, 9, 0, 0, 0, 3, 0, 2, 0, 6, 0, 0, 0, 0, 1, 0, 1, 4, 0, 0, 0,\n       4, 0, 3, 0, 0, 0, 0, 0, 1, 0, 0, 2, 5, 0, 0, 0, 3, 0, 3, 0, 6, 9,\n       0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 4, 0, 3, 0, 0, 0, 0, 1, 1, 0, 0, 2,\n       6, 0, 0, 1, 3, 0, 3, 0, 6, 9, 0, 0, 1, 0, 1, 0, 8, 0])), (array([0, 0, 2, 0, 4, 0, 6, 7, 0, 0, 0, 0, 2, 0, 9, 0, 0, 0, 3, 0, 2, 0,\n       6, 0, 0, 0, 0, 1, 0, 0, 3, 0, 1, 0, 2, 0, 4, 0, 6, 8, 0, 1, 0, 0,\n       2, 0, 9, 0, 0, 0, 3, 0, 2, 0, 6, 0, 0, 0, 0, 1, 0, 1, 4, 0, 0, 0,\n       4, 0, 3, 0, 0, 0, 0, 0, 1, 0, 0, 2, 5, 0, 0, 0, 3, 0, 3, 0, 6, 9,\n       0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 4, 0, 3, 0, 0, 0, 0, 1, 1, 0, 0, 2,\n       6, 0, 0, 1, 3, 0, 3, 0, 6, 9, 0, 0, 1, 0, 1, 0, 8, 0]), array([[2],\n       [0]]), array([[26],\n       [ 1]]), array([0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 9, 0, 0, 0, 3, 0, 2, 0,\n       0, 0, 0, 0, 0, 1, 1, 1, 4, 0, 0, 0, 1, 0, 1, 0, 3, 6, 0, 0, 0, 0,\n       2, 0, 9, 0, 1, 1, 3, 0, 2, 0, 0, 3, 0, 0, 1, 1, 2, 4, 4, 0, 0, 0,\n       4, 0, 4, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 4, 0, 4, 0, 6, 9,\n       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 5, 0, 4, 0, 0, 0, 1, 0, 1, 0, 0, 2,\n       4, 1, 0, 0, 4, 0, 4, 0, 6, 9, 1, 0, 1, 0, 4, 0, 6, 2])), (array([0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 9, 0, 0, 0, 3, 0, 2, 0,\n       0, 0, 0, 0, 0, 1, 1, 1, 4, 0, 0, 0, 1, 0, 1, 0, 3, 6, 0, 0, 0, 0,\n       2, 0, 9, 0, 1, 1, 3, 0, 2, 0, 0, 3, 0, 0, 1, 1, 2, 4, 4, 0, 0, 0,\n       4, 0, 4, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 4, 0, 4, 0, 6, 9,\n       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 5, 0, 4, 0, 0, 0, 1, 0, 1, 0, 0, 2,\n       4, 1, 0, 0, 4, 0, 4, 0, 6, 9, 1, 0, 1, 0, 4, 0, 6, 2]), array([[0],\n       [2]]), array([[ -2],\n       [-10]]), array([0, 0, 0, 0, 0, 0, 6, 1, 0, 0, 0, 0, 2, 0, 9, 0, 0, 0, 0, 0, 0, 0,\n       1, 0, 0, 0, 2, 3, 2, 4, 4, 0, 0, 0, 0, 1, 0, 0, 6, 1, 0, 0, 0, 0,\n       2, 0, 9, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 4, 2, 4, 5, 0, 0, 0,\n       6, 0, 6, 0, 0, 0, 0, 0, 1, 0, 2, 2, 1, 0, 0, 0, 4, 0, 5, 0, 6, 9,\n       0, 0, 3, 0, 4, 0, 1, 0, 0, 0, 6, 0, 6, 0, 0, 0, 0, 0, 2, 0, 2, 2,\n       1, 0, 0, 0, 4, 0, 5, 0, 6, 9, 0, 0, 4, 0, 4, 0, 1, 0]))], maxlen=10000)) and kwargs: {} for signature: (agent_idx, batch, agents, gamma=<captured_default_value>).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 114\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(replay_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m:\n\u001b[1;32m    113\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m--> 114\u001b[0m             \u001b[43mtrain_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;66;03m# new_weights = model_action.get_weights()\u001b[39;00m\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;66;03m# weights.append(new_weights)\u001b[39;00m\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;66;03m#print(f\"Episode {episode}: new weights = {new_weights}\")\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# if list_values:\u001b[39;00m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;66;03m#    # print(f'list values {list_values[-1]}')\u001b[39;00m\n\u001b[1;32m    126\u001b[0m traci\u001b[38;5;241m.\u001b[39msimulationStep()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/sumo_env/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/sumo_env/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py:446\u001b[0m, in \u001b[0;36mbind_function_inputs\u001b[0;34m(args, kwargs, function_type, default_values)\u001b[0m\n\u001b[1;32m    442\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mbind_with_defaults(\n\u001b[1;32m    443\u001b[0m       args, sanitized_kwargs, default_values\n\u001b[1;32m    444\u001b[0m   )\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 446\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    447\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBinding inputs to tf.function failed due to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived args: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and kwargs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msanitized_kwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for signature:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    450\u001b[0m   ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bound_arguments\n",
      "\u001b[0;31mTypeError\u001b[0m: Binding inputs to tf.function failed due to `missing a required argument: 'agents'`. Received args: (0, deque([(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), array([[1],\n       [3]]), array([[0],\n       [0]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])), (array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), array([[0],\n       [0]]), array([[-7],\n       [-7]]), array([0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0])), (array([0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0]), array([[1],\n       [3]]), array([[-19],\n       [-14]]), array([0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n       1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 5, 0, 1, 0, 1, 0,\n       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 2, 0, 0, 0,\n       1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1,\n       0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 0, 0, 1, 0, 0, 0, 0, 0])), (array([0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n       1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 5, 0, 1, 0, 1, 0,\n       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 2, 0, 0, 0,\n       1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1,\n       0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 0, 0, 1, 0, 0, 0, 0, 0]), array([[2],\n       [2]]), array([[-16],\n       [-13]]), array([0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       3, 0, 0, 0, 2, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 6, 1, 2, 0, 2, 0,\n       1, 0, 2, 0, 0, 1, 1, 0, 0, 0, 5, 0, 0, 0, 2, 2, 0, 1, 1, 0, 0, 0,\n       1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 1, 0, 1, 0, 0, 0, 0, 2, 2, 0, 1, 0, 0, 0, 0, 1, 4, 2, 1, 1,\n       2, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 2, 0, 1, 0, 1, 0])), (array([0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       3, 0, 0, 0, 2, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 6, 1, 2, 0, 2, 0,\n       1, 0, 2, 0, 0, 1, 1, 0, 0, 0, 5, 0, 0, 0, 2, 2, 0, 1, 1, 0, 0, 0,\n       1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 1, 0, 1, 0, 0, 0, 0, 2, 2, 0, 1, 0, 0, 0, 0, 1, 4, 2, 1, 1,\n       2, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 2, 0, 1, 0, 1, 0]), array([[2],\n       [2]]), array([[-15],\n       [-28]]), array([0, 0, 0, 0, 0, 0, 6, 2, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 1, 0,\n       5, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 6, 2, 1, 1, 1, 0,\n       0, 0, 5, 0, 1, 0, 2, 0, 1, 0, 5, 0, 0, 0, 1, 2, 0, 2, 2, 0, 0, 0,\n       2, 0, 2, 0, 0, 0, 0, 0, 4, 0, 4, 0, 3, 0, 0, 0, 1, 0, 0, 0, 1, 3,\n       0, 0, 2, 0, 2, 0, 2, 0, 0, 1, 3, 0, 2, 0, 0, 0, 0, 1, 5, 1, 4, 0,\n       3, 0, 0, 0, 2, 0, 0, 0, 2, 5, 0, 1, 2, 0, 2, 0, 2, 0])), (array([0, 0, 0, 0, 0, 0, 6, 2, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 1, 0,\n       5, 0, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 6, 2, 1, 1, 1, 0,\n       0, 0, 5, 0, 1, 0, 2, 0, 1, 0, 5, 0, 0, 0, 1, 2, 0, 2, 2, 0, 0, 0,\n       2, 0, 2, 0, 0, 0, 0, 0, 4, 0, 4, 0, 3, 0, 0, 0, 1, 0, 0, 0, 1, 3,\n       0, 0, 2, 0, 2, 0, 2, 0, 0, 1, 3, 0, 2, 0, 0, 0, 0, 1, 5, 1, 4, 0,\n       3, 0, 0, 0, 2, 0, 0, 0, 2, 5, 0, 1, 2, 0, 2, 0, 2, 0]), array([[2],\n       [2]]), array([[-23],\n       [-29]]), array([0, 0, 1, 0, 4, 0, 6, 3, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 2, 0, 2, 0,\n       6, 0, 0, 0, 0, 3, 0, 2, 3, 0, 0, 0, 2, 0, 4, 0, 6, 4, 0, 0, 1, 1,\n       0, 0, 5, 0, 0, 0, 2, 0, 2, 0, 6, 0, 0, 0, 0, 4, 0, 3, 3, 0, 0, 0,\n       3, 0, 2, 0, 0, 0, 0, 0, 6, 0, 6, 0, 3, 0, 0, 0, 2, 0, 2, 0, 6, 5,\n       0, 0, 3, 0, 2, 0, 3, 0, 0, 0, 3, 0, 2, 0, 0, 0, 1, 0, 6, 1, 6, 0,\n       3, 0, 0, 0, 2, 0, 2, 0, 6, 5, 0, 0, 4, 0, 3, 0, 4, 0])), (array([0, 0, 1, 0, 4, 0, 6, 3, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 2, 0, 2, 0,\n       6, 0, 0, 0, 0, 3, 0, 2, 3, 0, 0, 0, 2, 0, 4, 0, 6, 4, 0, 0, 1, 1,\n       0, 0, 5, 0, 0, 0, 2, 0, 2, 0, 6, 0, 0, 0, 0, 4, 0, 3, 3, 0, 0, 0,\n       3, 0, 2, 0, 0, 0, 0, 0, 6, 0, 6, 0, 3, 0, 0, 0, 2, 0, 2, 0, 6, 5,\n       0, 0, 3, 0, 2, 0, 3, 0, 0, 0, 3, 0, 2, 0, 0, 0, 1, 0, 6, 1, 6, 0,\n       3, 0, 0, 0, 2, 0, 2, 0, 6, 5, 0, 0, 4, 0, 3, 0, 4, 0]), array([[2],\n       [2]]), array([[-12],\n       [ 10]]), array([0, 0, 2, 0, 4, 0, 6, 6, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 2, 0, 2, 0,\n       6, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 4, 0, 6, 6, 4, 1, 1, 1,\n       1, 1, 8, 0, 0, 2, 3, 0, 2, 0, 6, 0, 1, 0, 0, 1, 1, 0, 3, 0, 0, 0,\n       3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0, 2, 0, 6, 7,\n       0, 0, 0, 0, 0, 0, 6, 0, 1, 4, 4, 0, 3, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n       4, 0, 0, 0, 3, 0, 3, 0, 6, 8, 2, 0, 1, 0, 0, 0, 6, 0])), (array([0, 0, 2, 0, 4, 0, 6, 6, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 2, 0, 2, 0,\n       6, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 4, 0, 6, 6, 4, 1, 1, 1,\n       1, 1, 8, 0, 0, 2, 3, 0, 2, 0, 6, 0, 1, 0, 0, 1, 1, 0, 3, 0, 0, 0,\n       3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0, 2, 0, 6, 7,\n       0, 0, 0, 0, 0, 0, 6, 0, 1, 4, 4, 0, 3, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n       4, 0, 0, 0, 3, 0, 3, 0, 6, 8, 2, 0, 1, 0, 0, 0, 6, 0]), array([[0],\n       [1]]), array([[ -3],\n       [-12]]), array([0, 0, 2, 0, 4, 0, 6, 7, 0, 0, 0, 0, 2, 0, 9, 0, 0, 0, 3, 0, 2, 0,\n       6, 0, 0, 0, 0, 1, 0, 0, 3, 0, 1, 0, 2, 0, 4, 0, 6, 8, 0, 1, 0, 0,\n       2, 0, 9, 0, 0, 0, 3, 0, 2, 0, 6, 0, 0, 0, 0, 1, 0, 1, 4, 0, 0, 0,\n       4, 0, 3, 0, 0, 0, 0, 0, 1, 0, 0, 2, 5, 0, 0, 0, 3, 0, 3, 0, 6, 9,\n       0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 4, 0, 3, 0, 0, 0, 0, 1, 1, 0, 0, 2,\n       6, 0, 0, 1, 3, 0, 3, 0, 6, 9, 0, 0, 1, 0, 1, 0, 8, 0])), (array([0, 0, 2, 0, 4, 0, 6, 7, 0, 0, 0, 0, 2, 0, 9, 0, 0, 0, 3, 0, 2, 0,\n       6, 0, 0, 0, 0, 1, 0, 0, 3, 0, 1, 0, 2, 0, 4, 0, 6, 8, 0, 1, 0, 0,\n       2, 0, 9, 0, 0, 0, 3, 0, 2, 0, 6, 0, 0, 0, 0, 1, 0, 1, 4, 0, 0, 0,\n       4, 0, 3, 0, 0, 0, 0, 0, 1, 0, 0, 2, 5, 0, 0, 0, 3, 0, 3, 0, 6, 9,\n       0, 0, 1, 0, 0, 0, 7, 0, 0, 0, 4, 0, 3, 0, 0, 0, 0, 1, 1, 0, 0, 2,\n       6, 0, 0, 1, 3, 0, 3, 0, 6, 9, 0, 0, 1, 0, 1, 0, 8, 0]), array([[2],\n       [0]]), array([[26],\n       [ 1]]), array([0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 9, 0, 0, 0, 3, 0, 2, 0,\n       0, 0, 0, 0, 0, 1, 1, 1, 4, 0, 0, 0, 1, 0, 1, 0, 3, 6, 0, 0, 0, 0,\n       2, 0, 9, 0, 1, 1, 3, 0, 2, 0, 0, 3, 0, 0, 1, 1, 2, 4, 4, 0, 0, 0,\n       4, 0, 4, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 4, 0, 4, 0, 6, 9,\n       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 5, 0, 4, 0, 0, 0, 1, 0, 1, 0, 0, 2,\n       4, 1, 0, 0, 4, 0, 4, 0, 6, 9, 1, 0, 1, 0, 4, 0, 6, 2])), (array([0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 9, 0, 0, 0, 3, 0, 2, 0,\n       0, 0, 0, 0, 0, 1, 1, 1, 4, 0, 0, 0, 1, 0, 1, 0, 3, 6, 0, 0, 0, 0,\n       2, 0, 9, 0, 1, 1, 3, 0, 2, 0, 0, 3, 0, 0, 1, 1, 2, 4, 4, 0, 0, 0,\n       4, 0, 4, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 4, 0, 4, 0, 6, 9,\n       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 5, 0, 4, 0, 0, 0, 1, 0, 1, 0, 0, 2,\n       4, 1, 0, 0, 4, 0, 4, 0, 6, 9, 1, 0, 1, 0, 4, 0, 6, 2]), array([[0],\n       [2]]), array([[ -2],\n       [-10]]), array([0, 0, 0, 0, 0, 0, 6, 1, 0, 0, 0, 0, 2, 0, 9, 0, 0, 0, 0, 0, 0, 0,\n       1, 0, 0, 0, 2, 3, 2, 4, 4, 0, 0, 0, 0, 1, 0, 0, 6, 1, 0, 0, 0, 0,\n       2, 0, 9, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 4, 2, 4, 5, 0, 0, 0,\n       6, 0, 6, 0, 0, 0, 0, 0, 1, 0, 2, 2, 1, 0, 0, 0, 4, 0, 5, 0, 6, 9,\n       0, 0, 3, 0, 4, 0, 1, 0, 0, 0, 6, 0, 6, 0, 0, 0, 0, 0, 2, 0, 2, 2,\n       1, 0, 0, 0, 4, 0, 5, 0, 6, 9, 0, 0, 4, 0, 4, 0, 1, 0]))], maxlen=10000)) and kwargs: {} for signature: (agent_idx, batch, agents, gamma=<captured_default_value>)."
     ]
    }
   ],
   "source": [
    "rewards = []\n",
    "best_score = 0\n",
    "reward = 0\n",
    "total_reward = 0\n",
    "list_values = []\n",
    "weights = []\n",
    "replay_buffer = deque(maxlen=10000)\n",
    "\n",
    "epoch = 500\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# PERIODE DE STABILITE\n",
    "\n",
    "# traffic_scale = [0.1] * 100\n",
    "# AUGMENTATION DE TRAFFIC\n",
    "# traffic_scale.extend(np.linspace(0.1, 1, 400, dtype=float))\n",
    "# OR\n",
    "#traffic_scale = 0.2\n",
    "\n",
    "\n",
    "\n",
    "for episode in range(epoch):\n",
    "    #SEED & TRAFFIC SCALING\n",
    "    seed_value = np.random.randint(1000)\n",
    "    #seed_value = 41\n",
    "    if traci.isLoaded():\n",
    "        traci.close()\n",
    "\n",
    "\n",
    "    sumoCmd = [sumo_bin, \"-c\", simulConfig, \"--start\"]\n",
    "\n",
    "    traci.start(sumoCmd)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    lane_ids =  traci.lane.getIDList()\n",
    "    # print(lane_ids[0])\n",
    "\n",
    "    traffic_light_ids = traci.trafficlight.getIDList()\n",
    "\n",
    "    # state = np.array(queue(lane_ids))\n",
    "\n",
    "    b = traffic_light_ids[0]\n",
    "\n",
    "# REMPLACER B PAR LE FEU 2\n",
    "\n",
    "\n",
    "    state_tf_one=np.array(get_state_per_traffic_light(traffic_light_ids[0]))\n",
    "    state_tf_two = np.array(get_state_per_traffic_light(traffic_light_ids[1]))\n",
    "    action_tf_one=-1\n",
    "    action_tf_two=-1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # print(state)\n",
    "    for step in range(80000): ## TO CHANGED\n",
    "        epsilon = max(1 - episode / epoch, 0.01)\n",
    "\n",
    "        if step%2000 == 0:\n",
    "            #print(f\"longeur du buffer :{len(replay_buffer)}\")\n",
    "            ########################################################################\n",
    "            ##Calcul de la reward\n",
    "            # next_state = np.array(queue(lane_ids))\n",
    "            next_state_tf_one = np.array(get_state_per_traffic_light(traffic_light_ids[0]))\n",
    "            next_state_tf_two = np.array(get_state_per_traffic_light(traffic_light_ids[1]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # 4 pour l'action dim car chaque feu à 4 phases\n",
    "            noise_one = np.random.normal(0, 0.1, size=4)\n",
    "            noise_two = np.random.normal(0, 0.1, size=4)\n",
    "            print(\"shape\", state_tf_one.shape)\n",
    "            print(\"shape\", state_tf_two.shape)\n",
    "            action_tf_one = model_action_one_tf_light.predict(state_tf_one[np.newaxis]) + noise_one\n",
    "            action_tf_two = model_action_second_tf_light(state_tf_two[np.newaxis]) + noise_two\n",
    "            action_tf_one = np.argmax(action_tf_one).reshape(1,1)\n",
    "            action_tf_two = np.argmax(action_tf_two).reshape(1,1)\n",
    "\n",
    "\n",
    "            # reward = calculate_reward(values, reward, total_reward)[0]\n",
    "            # reward=(np.sum(state)-np.sum(next_state))\n",
    "            reward_tf_one = np.sum(state_tf_one)- np.sum(next_state_tf_one)\n",
    "            reward_tf_two = np.sum(state_tf_two)- np.sum(next_state_tf_two)\n",
    "            reward_tf_one = reward_tf_one.reshape(1,1)\n",
    "            reward_tf_two = reward_tf_two.reshape(1,1)\n",
    "\n",
    "            states = np.concat([state_tf_one, state_tf_two])\n",
    "            actions = np.concat([action_tf_one, action_tf_two])\n",
    "            rewards = np.concat([reward_tf_one, reward_tf_two])\n",
    "            next_states = np.concat([next_state_tf_one, next_state_tf_two])\n",
    "\n",
    "\n",
    "            replay_buffer.append((states, actions, rewards, next_states))\n",
    "            #########################################################################\n",
    "            state_tf_one=next_state_tf_one\n",
    "            state_tf_two = next_state_tf_two\n",
    "\n",
    "\n",
    "            print(\"action\", action_tf_one)\n",
    "            traci.trafficlight.setPhase(traffic_light_ids[0],2*int(action_tf_one))\n",
    "            traci.trafficlight.setPhase(traffic_light_ids[0],2*int(action_tf_two))\n",
    "\n",
    "            if len(replay_buffer) >= 10:\n",
    "                 for agent in range(2):\n",
    "                    train_agent(agent, replay_buffer)\n",
    "\n",
    "                # new_weights = model_action.get_weights()\n",
    "                # weights.append(new_weights)\n",
    "                #print(f\"Episode {episode}: new weights = {new_weights}\")\n",
    "            # else:\n",
    "            #     print(f\"Episode {episode}: pas assez de données dans le replay buffer.\")\n",
    "            # print(values)\n",
    "            # if list_values:\n",
    "            #    # print(f'list values {list_values[-1]}')\n",
    "\n",
    "\n",
    "        traci.simulationStep()\n",
    "    print(f'episode : {episode}')\n",
    "    traci.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = []\n",
    "best_score = 0\n",
    "reward = 0\n",
    "total_reward = 0\n",
    "list_values = []\n",
    "weights = []\n",
    "wait_times = []\n",
    "# replay_buffer = deque(maxlen=2000)\n",
    "\n",
    "#SEED é SCALE\n",
    "seed_value = np.random.randint(1000)\n",
    "#seed_value = 41\n",
    "traffic_scale = 0.2\n",
    "\n",
    "\n",
    "#LAUNCH\n",
    "sumoCmd = [sumo_gui_bin, \"-c\", simulConfig, \"--start\", \"--seed\", str(seed_value), '--scale', str(traffic_scale), '--gui-settings-file', 'full_state_sumo_gui_settings.xml']\n",
    "\n",
    "# if traci.isLoaded():\n",
    "#     traci.close()\n",
    "traci.start(sumoCmd)\n",
    "lane_ids =  traci.lane.getIDList()\n",
    "# print(lane_ids[0])\n",
    "# for lane in lane_ids:\n",
    "#     print(traci.lane.getLastStepVehicleNumber(lane))\n",
    "# north_lane = traci.lane.getLastStepVehicleNumber(\"N_0\")\n",
    "# south_lane = traci.lane.getLastStepVehicleNumber(\"S_0\")\n",
    "# east_lane = traci.lane.getLastStepVehicleNumber(\"E_0\")\n",
    "# west_lane = traci.lane.getLastStepVehicleNumber(\"W_0\")\n",
    "trafic_light_ids = traci.trafficlight.getIDList()\n",
    "\n",
    "state = np.array(get_state(lane_ids))\n",
    "action=-1\n",
    "# print(state)\n",
    "wait_times.append(0)\n",
    "for step in range(100000): ## TO CHANGED\n",
    "    #epsilon = max(1 - episode / 10, 0.01)\n",
    "    nom_du_feu= traci.trafficlight.getIDList()[0]\n",
    "\n",
    "    if step%2000 == 0:\n",
    "        state=np.array(get_state(lane_ids))\n",
    "        action = epsilon_greedy_policy(state,0)*2\n",
    "        #action = np.random.randint(3)\n",
    "        print(\"action\", action)\n",
    "        #print(traci.trafficlight.getAllProgramLogics(nom_du_feu))\n",
    "\n",
    "        #print(traci.trafficlight.getAllProgramLogics(nom_du_feu)[0].phases[action])\n",
    "        traci.trafficlight.setPhase(trafic_light_ids[0],action)\n",
    "    traci.simulationStep()\n",
    "\n",
    "traci.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sumo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
